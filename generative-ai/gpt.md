# GPT

## Precursor

1. [Proximal Policy Optimization](https://openai.com/research/openai-baselines-ppo) (PPO) - an RL algorithm, PPO is better than state-of-the-art approaches while being much simpler to implement and tune and is the default reinforcement learning algorithm at OpenAI.
2. [Learning from human preference](https://openai.com/research/learning-from-human-preferences) (human in the loop) - a method used to infer what humans want by being told which of two proposed behaviors is better.
3. [instructGPT](https://openai.com/research/instruction-following) - arguably better at following user intentions than GPT-3 while also making them more truthful and less toxic, using human in the loop.

## Articles

1. [what is chatGPT doing and why does it work?](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/) explaining next word prediction in detail.
2. [Karpathy on building GPT](https://www.youtube.com/watch?v=kCc8FmEb1nY\&t=191s)
3. [Is DPO Superior to PPO for LLM Alignment](https://arxiv.org/pdf/2404.10719)? A Comprehensive Study - "PPO is able to surpass other alignment methods in all cases and achieve state-of-the-art results in challenging code competitions."

## Competitions

1. GPT 4 [Hackathon code results](https://docs.google.com/spreadsheets/d/1tmfn8jKb7T1x7PpyO7rD023tH2zc\_WDg\_OHh0aVXIrw/edit#gid=174517450)
2. [LangChain Gen Hackathon](https://docs.google.com/spreadsheets/d/1GqwPo1FpAbe\_awmNZW5ZMH69yc5QtEr7ZYw-ckaz\_mQ/edit#gid=795016726)

## Tools

1. Sentence Embeddings
   1. [sentence embedding for semantic search](https://github.com/Muennighoff/sgpt)
   2. [GPT 3 Dense sentence embeddings](https://medium.com/@nils\_reimers/openai-gpt-3-text-embeddings-really-a-new-state-of-the-art-in-dense-text-embeddings-6571fe3ec9d9)

## Virtual assistants

1. [flowGPT](https://flowgpt.com/) - has many bots, prompts.
